{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60672a1",
   "metadata": {},
   "source": [
    "# **FB-31 Vasalatii Anton, Task 4** \n",
    "___\n",
    "## ***Dataset*** \n",
    "**Source**: Chen, S. (2015). Beijing PM2.5 [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5JS49.\n",
    "\n",
    "**General**: This hourly data set contains the PM2.5 data of US Embassy in Beijing. Meanwhile, meteorological data from Beijing Capital International Airport are also included.  \n",
    "\n",
    "**Subject Area**: Climate and Environment  \n",
    "\n",
    "**Associated Tasks**:  Regression\n",
    "\n",
    "**Dataset Characteristics**: Multivariate, Time-Series  \n",
    "\n",
    "**Instances**: 43824  \n",
    "\n",
    "**Columns count**: 13 \n",
    "\n",
    "**Missing values**: Yes  \n",
    "\n",
    "**Additional info**: The data's time period is between Jan 1st, 2010 to Dec 31st, 2014. Missing data are denoted as \"NA\".\n",
    "___\n",
    "### **Variables info**\n",
    "**No**: row number\n",
    "\n",
    "**year**: year of data in this row\n",
    "\n",
    "**month**: month of data in this row\n",
    "\n",
    "**day**: day of data in this row\n",
    "\n",
    "**hour**: hour of data in this row\n",
    "\n",
    "**pm2.5**: PM2.5 concentration\n",
    "\n",
    "**DEWP**: Dew Point\n",
    "\n",
    "**TEMP**: Temperature\n",
    "\n",
    "**PRES**: Pressure\n",
    "\n",
    "**cbwd**: Combined wind direction\n",
    "\n",
    "**Iws**: Cumulated wind speed  \n",
    "\n",
    "**Is**: Cumulated hours of snow\n",
    "\n",
    "**Ir**: Cumulated hours of rain  \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0037735",
   "metadata": {},
   "source": [
    "**Setup imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf509c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Style\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab4dad",
   "metadata": {},
   "source": [
    "**Additional functions that use python-tabulate and colorama to make output beautiful** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2387cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(frame):\n",
    "    print(Fore.LIGHTCYAN_EX + tabulate.tabulate(frame, headers='keys', tablefmt=\"heavy_grid\", showindex=False) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ff0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_delimiter():\n",
    "    print(Fore.LIGHTMAGENTA_EX+\"_\"*135+\"\\n\"+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_double_delimiter():\n",
    "    print(Fore.LIGHTYELLOW_EX+\"_\"*135+\"\\n\"+\"_\"*135+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0956bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_green_cyan_colored_pair(tag, value, indentation=''):\n",
    "    print(indentation + Fore.LIGHTGREEN_EX + tag + \" \" + Fore.CYAN + str(value) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67b8ec",
   "metadata": {},
   "source": [
    "**Parsing data with Pandas**  \n",
    "Here we read cleaned, normalized and divided into clusters data that also was used in previous task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['No', 'Year', 'Month', 'Day', 'Hour', 'PM2.5', 'DEWP', 'TEMP', 'PRES', 'CBWD', 'IWS','IS','IR','PM2.5_Orig','TEMP_Orig','KMeansCluster', 'AgglomerativeCluster']\n",
    "df = pd.read_csv(\"beijing_pm_2_5_cleared_clustered.csv\",delimiter=\",\",index_col=False, header=1, na_values=['NA'], names=headers)\n",
    "print_df(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e4524",
   "metadata": {},
   "source": [
    "### **Classification usign K-Nearest Neighbours method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc547b67",
   "metadata": {},
   "source": [
    "**Splitting dataset into two parts (70% for training, 30% for testing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['PM2.5_Orig','TEMP_Orig']]\n",
    "y = df['KMeansCluster']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c46839",
   "metadata": {},
   "source": [
    "**Scaling data for choosing best K and final training/testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scailed = scaler.fit_transform(x)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c14bcd",
   "metadata": {},
   "source": [
    "**Choosing best K by trying different options in range 1..21**  \n",
    "Here we do cross-validation on 3 blocks for every K in range and then  \n",
    "we calculate mean of cross-validation scores to compare with other options results   \n",
    "As example was used code provided in https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5698a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [i for i in range (4,21)]\n",
    "scores = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score = cross_val_score(knn, x_scailed, y, cv=KFold(n_splits=3,shuffle=True))\n",
    "    scores.append((k,np.mean(score)))\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['K','Score'])\n",
    "\n",
    "print_df(scores_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=scores_df,x=\"K\",y=\"Score\", marker='o',linewidth=2.5,markersize=8,color='royalblue'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"K\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Accuracy Score\", fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.title(\"Accuracy Score by different K\", fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13af2c",
   "metadata": {},
   "source": [
    "As we can see from the table and plot above every K, we tried, gives us excellent accuracy that is higher than 85%,  \n",
    "so we can use every K in range 4..20 (we start from n+1, where n is classes amount). Let's choose 5 because it has the best score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64806a5b",
   "metadata": {},
   "source": [
    "**Getting the final accuracy score for the data split at the beginning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "y_pred = knn.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print_green_cyan_colored_pair(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9822f3e",
   "metadata": {},
   "source": [
    "**Doing cross-validation with 3 blocks on final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24baa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cv_scores = cross_val_score(knn, x_scailed, y, cv=KFold(n_splits=3,shuffle=True))\n",
    "for i, score in enumerate(final_cv_scores):\n",
    "    print_green_cyan_colored_pair(f\"Score {i+1}:\",score)\n",
    "print_green_cyan_colored_pair(\"Mean score\", final_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b85dc4",
   "metadata": {},
   "source": [
    "**Visualizing decision boundary as in previous Task3**  \n",
    "  \n",
    "Useful post: https://stackoverflow.com/questions/45075638/graph-k-nn-decision-boundaries-in-matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "\n",
    "x_min, x_max = x.iloc[:, 0].min() - 1, x.iloc[:, 0].max() + 1\n",
    "y_min, y_max = x.iloc[:, 1].min() - 1, x.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "mesh_points_df = pd.DataFrame(mesh_points, columns=x.columns)\n",
    "Z = knn.predict(scaler.transform(mesh_points_df))\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)\n",
    "plt.scatter(x.iloc[:, 0], x.iloc[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "plt.xlabel('PM2.5', fontweight=\"bold\", fontsize=12)\n",
    "plt.ylabel('TEMP', fontweight=\"bold\", fontsize=12)\n",
    "plt.title('KNN Decision Boundary', fontweight=\"bold\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb086a4",
   "metadata": {},
   "source": [
    "### **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a4c20",
   "metadata": {},
   "source": [
    "**In this task, we practically used the K-nearest neighbors method to classify the dataset that we used in the previous tasks.  \n",
    "First, we tried to find a K in the range 4..20 (we started with n+1, where n is the number of classes), which gives us an accuracy score of more than 85%.  \n",
    "In this case, we could have used any K in this range, but we decided to choose 5 because it gave the best score and would also be faster compared to other options with a close but lower score, such as 12, 15 or 17, etc., due to the fewer calculations. \n",
    "Then, we tried to use a model with K=5, fitted on 65% of the dataset, to check the score on 35% of the test part.  \n",
    "And finally, we performed cross-validation with 3 folds, which also gave us a high score, almost similar to the predicted test part score.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
